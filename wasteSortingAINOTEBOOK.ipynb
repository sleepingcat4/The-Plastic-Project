{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wbowers/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical                 \n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, RandomRotation, RandomFlip, RandomZoom, RandomContrast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from PIL import ImageFile\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "tf.config.set_soft_device_placement(True) \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 486), (1, 486), (2, 486), (3, 486), (4, 486), (5, 486)]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "img_res = [224, 224]\n",
    "dataset = \"dataset-v2\"\n",
    "categories = os.listdir(os.getcwd() + \"/\" + dataset)\n",
    "weird_count = 0\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(categories))):\n",
    "    for filename in tqdm(os.listdir(os.getcwd() + '/' + dataset + '/' + categories[i] + '/'), leave=False):\n",
    "        image = im.open(os.getcwd() + '/' + dataset + '/' + categories[i] + '/' + filename)\n",
    "        np_img = np.array(image.resize((img_res[1], img_res[0])))\n",
    "        if np_img.shape == (img_res[0], img_res[1], 3):\n",
    "            images.append(np_img)\n",
    "            labels.append(i)\n",
    "            count += 1\n",
    "\n",
    "# split into train and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, train_size=0.8, random_state=1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "# reshape data into 2d arrays so it can be processed\n",
    "nsamples, nx, ny, d3 = X_train.shape\n",
    "X_train = X_train.reshape((nsamples,d3*nx*ny))\n",
    "\n",
    "# Randomly oversample minority classes\n",
    "X_train_ros, y_train_ros= SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "# Check distribution of data across classes\n",
    "print(sorted(Counter(y_train_ros).items()))\n",
    "\n",
    "# resize data back into original shape\n",
    "nsamples = X_train_ros.shape[0]\n",
    "X_train_ros = X_train_ros.reshape((nsamples, nx, ny, d3))\n",
    "\n",
    "X_train = X_train_ros\n",
    "y_train = y_train_ros\n",
    "\n",
    "# some preprocessing on the data\n",
    "\n",
    "# normalizing the data to be from 0-1 instead 1-255\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# format the target data to match the output data of the cnn\n",
    "# so you can compare the two\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:21:03.586213: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-27 16:21:03.586362: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,430,854\n",
      "Trainable params: 172,742\n",
      "Non-trainable params: 2,258,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "with tf.device('/cpu:0'):\n",
    "    data_augmentation = k.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2, input_shape=(img_res[0], img_res[1], 3)),\n",
    "    RandomZoom(0.2, 0.2),\n",
    "    RandomContrast(0.2),\n",
    "    ])\n",
    "\n",
    "base_model = k.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_res[0], img_res[1], 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = k.Input(shape=(img_res[0], img_res[1], 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x)\n",
    "x = k.layers.GlobalAveragePooling2D() (x)\n",
    "x = k.layers.Dense(128) (x)\n",
    "x = k.layers.Dropout(0.2) (x)\n",
    "x = k.layers.Dense(64) (x)\n",
    "x = k.layers.Dropout(0.2) (x)\n",
    "x = k.layers.BatchNormalization() (x)\n",
    "outputs = k.layers.Dense(len(categories), activation = 'softmax') (x)\n",
    "\n",
    "model = k.Model(inputs, outputs)\n",
    "\n",
    "base_learning_rate = 0.0016\n",
    "\n",
    "model.compile(optimizer=k.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss=k.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "with tf.device('/cpu:0'):\n",
    "    data_augmentation_light = k.Sequential([\n",
    "    RandomRotation(0.1, input_shape=(img_res[0], img_res[1], 3)),\n",
    "    ])\n",
    "\n",
    "    data_augmentation_heavy = k.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2, input_shape=(img_res[0], img_res[1], 3)),\n",
    "    RandomZoom(0.2, 0.2),\n",
    "    #RandomContrast(0.2),\n",
    "    ])\n",
    "\n",
    "base_model = k.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_res[0], img_res[1], 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = k.Input(shape=(img_res[0], img_res[1], 3))\n",
    "x = data_augmentation_heavy(inputs)\n",
    "x = base_model(x)\n",
    "x = k.layers.GlobalAveragePooling2D() (x)\n",
    "x = k.layers.Dense(128) (x)\n",
    "x = k.layers.Dropout(0.2) (x)\n",
    "x = k.layers.Dense(64) (x)\n",
    "x = k.layers.Dropout(0.2) (x)\n",
    "x = k.layers.BatchNormalization() (x)\n",
    "outputs = k.layers.Dense(len(categories), activation = 'softmax') (x)\n",
    "\n",
    "model = k.Model(inputs, outputs)\n",
    "\n",
    "learning_rate = 0.0015\n",
    "\n",
    "model.compile(optimizer=k.optimizers.Adam(learning_rate = learning_rate),\n",
    "                loss=k.losses.CategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with keras tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "data_aug_heavy (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "dense1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
      "dropout1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "dense2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "dropout2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "batchnorm (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# data augmentation\n",
    "with tf.device('/cpu:0'):\n",
    "    data_augmentation_light = k.Sequential([\n",
    "    RandomRotation(0.1, input_shape=(img_res[0], img_res[1], 3)),\n",
    "    ])\n",
    "\n",
    "    data_augmentation_heavy = k.Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2, input_shape=(img_res[0], img_res[1], 3)),\n",
    "    RandomZoom(0.2, 0.2),\n",
    "    #RandomContrast(0.2),\n",
    "    ])\n",
    "\n",
    "base_model = k.applications.MobileNetV2(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_res[0], img_res[1], 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    inputs = k.Input(shape=(img_res[0], img_res[1], 3))\n",
    "    if hp.Boolean(\"data_aug_heavy\"):\n",
    "        x = data_augmentation_heavy(inputs)\n",
    "    else:\n",
    "        x = data_augmentation_light(inputs)\n",
    "    x = base_model(x)\n",
    "    x = k.layers.GlobalAveragePooling2D() (x)\n",
    "    x = k.layers.Dense(units=hp.Int(\"dense1\", min_value=32, max_value=1024, step=32),) (x)\n",
    "    if hp.Boolean(\"dropout1\"):\n",
    "        x = k.layers.Dropout(0.2) (x)\n",
    "    x = k.layers.Dense(units=hp.Int(\"dense2\", min_value=32, max_value=512, step=32),) (x)\n",
    "    if hp.Boolean(\"dropout2\"):\n",
    "        x = k.layers.Dropout(0.2) (x)\n",
    "    if hp.Boolean(\"batchnorm\"):\n",
    "        x = k.layers.BatchNormalization() (x)\n",
    "    outputs = k.layers.Dense(len(categories), activation = 'softmax') (x)\n",
    "\n",
    "    model = k.Model(inputs, outputs)\n",
    "\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model.compile(optimizer=k.optimizers.Adam(learning_rate = learning_rate),\n",
    "                  loss=k.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"keras_tuner-model\",\n",
    "    project_name=\"waste_classification_model\",\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [02h 17m 22s]\n",
      "val_accuracy: 0.39726026852925617\n",
      "\n",
      "Best val_accuracy So Far: 0.4383561611175537\n",
      "Total elapsed time: 03h 06m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=3, validation_split = 0.1, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,439,750\n",
      "Trainable params: 181,510\n",
      "Non-trainable params: 2,258,240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "model = build_model(best_hps[0])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:17:52.664119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - ETA: 0s - loss: 0.8850 - categorical_crossentropy: 0.8850 - accuracy: 0.6917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:18:08.131988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "328/328 [==============================] - 23s 56ms/step - loss: 0.8850 - categorical_crossentropy: 0.8850 - accuracy: 0.6917 - val_loss: 2.2909 - val_categorical_crossentropy: 2.2909 - val_accuracy: 0.4623\n",
      "Epoch 2/5\n",
      "327/328 [============================>.] - ETA: 0s - loss: 0.6296 - categorical_crossentropy: 0.6296 - accuracy: 0.7706Saving model...\n",
      "328/328 [==============================] - 13s 40ms/step - loss: 0.6304 - categorical_crossentropy: 0.6304 - accuracy: 0.7706 - val_loss: 2.6210 - val_categorical_crossentropy: 2.6210 - val_accuracy: 0.4863\n",
      "Epoch 3/5\n",
      "327/328 [============================>.] - ETA: 0s - loss: 0.5774 - categorical_crossentropy: 0.5774 - accuracy: 0.7852Saving model...\n",
      "328/328 [==============================] - 13s 40ms/step - loss: 0.5766 - categorical_crossentropy: 0.5766 - accuracy: 0.7854 - val_loss: 2.8637 - val_categorical_crossentropy: 2.8637 - val_accuracy: 0.4521\n",
      "Epoch 4/5\n",
      "327/328 [============================>.] - ETA: 0s - loss: 0.5284 - categorical_crossentropy: 0.5284 - accuracy: 0.8070Saving model...\n",
      "328/328 [==============================] - 13s 40ms/step - loss: 0.5280 - categorical_crossentropy: 0.5280 - accuracy: 0.8072 - val_loss: 2.7869 - val_categorical_crossentropy: 2.7869 - val_accuracy: 0.4726\n",
      "Epoch 5/5\n",
      "328/328 [==============================] - ETA: 0s - loss: 0.4763 - categorical_crossentropy: 0.4763 - accuracy: 0.8293Saving model...\n",
      "328/328 [==============================] - 13s 40ms/step - loss: 0.4763 - categorical_crossentropy: 0.4763 - accuracy: 0.8293 - val_loss: 3.3967 - val_categorical_crossentropy: 3.3967 - val_accuracy: 0.4247\n",
      "16/16 [==============================] - 3s 141ms/step - loss: 0.6103 - categorical_crossentropy: 0.6103 - accuracy: 0.7747\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, validation_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, callbacks\u001b[39m=\u001b[39m[SaveModelCallback()])\n\u001b[1;32m     21\u001b[0m \u001b[39m# evalutating the loss/accuracy of the model on the test set\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mloss / crossentropy / accuracy:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(loss)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "epoch_counter = 1\n",
    "\n",
    "# save the data to a file that can later be converted to the CoreML format\n",
    "class SaveModelCallback(k.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global epoch_counter\n",
    "        print(\"Saving model...\")\n",
    "        self.model.save(\"model_epoch_\" + str(epoch_counter) + \".h5\")\n",
    "        epoch_counter += 1\n",
    "        \n",
    "# actually running the cnn and fitting/training neural network on the data\n",
    "# batch size = after 64 samples, make a small adjustment\n",
    "# epoch = every time all the data is run through, make a big adjustment\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model.compile(optimizer='adam', \n",
    "                loss=k.losses.CategoricalCrossentropy(),\n",
    "                metrics=[k.metrics.CategoricalCrossentropy(name='categorical_crossentropy'),'accuracy'])           \n",
    "    history = model.fit(X_train, y_train, epochs=5, batch_size=8, validation_split=0.1, shuffle = True, callbacks=[SaveModelCallback()])\n",
    "\n",
    "\n",
    "# evalutating the loss/accuracy of the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"loss / crossentropy / accuracy:\")\n",
    "print(loss)\n",
    "print(accuracy)\n",
    "\n",
    "\"\"\"\n",
    "IF MODEL DOESNT KNOW, RETURN GARBAGE AND SAY WE'RE NOT QUITE SURE\n",
    "Resource: https://www.ridwell.com/\n",
    "\"\"\"\n",
    "\n",
    "acc = history.history['accuracy'] # get history report of the model\n",
    "\n",
    "val_acc = history.history['val_accuracy'] # get history of the validation set\n",
    "\n",
    "loss = history.history['loss'] #get the history of the lossses recorded on the train set\n",
    "val_loss = history.history['val_loss'] #get the history of the lossses recorded on the validation set\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred = (y_pred > 0.5) \n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=categories, digits=4))\n",
    "\n",
    "\n",
    "\n",
    "# visualize 24 random results\n",
    "sns.set(font_scale=1)\n",
    "index = np.random.choice(np.arange(len(X_test)), 12, replace=False)    # pick 24 random smamples\n",
    "figure, axes = plt.subplots(nrows=3, ncols=4, figsize=(16,9))           # set dimensions\n",
    "for item in zip(axes.ravel(), X_test[index], y_test[index], y_pred[index]):          # put each sample into a \"slot\" in the table\n",
    "    axes, image, target, predict = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])\n",
    "    print(target)\n",
    "    axes.set_title(\"label: \" + categories[np.argmax(target)] + '''\n",
    "    predicted: ''' + categories[np.argmax(predict)])\n",
    "plt.tight_layout()\n",
    "plt.show()             "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d921013406d8a81898f1eed854dda0de0e86e337e77a6934b5c3f20e334a681c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
